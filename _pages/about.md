---
layout: about
title: About
permalink: /
subtitle: SUSTech, Shenzhen, China

profile:
  align: right
  image: g&gary.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 blog posts
  limit: 3 # leave blank to include all the blog posts
---

I am a PhD candidate in the Department of Computer Science and Engineering at <a href="https://www.sustech.edu.cn/">Southern University of Science and Technology</a> in Shenzhen, China, under the supervision of Associate Professor <a href="https://cse.sustech.edu.cn/faculty/~weixt/">Xuetao Wei</a>. Before my PhD, I worked as a research assistant,  under the supervision of Professor <a href="https://jqyu.me/en/index.html">James Jianqiao Yu</a>. Both mentors have provided invaluable guidance and support throughout my academic journey.

<hr class="divider" />

My research interests lie at the intersection of computer science, economics, and sociology, focusing on fairness in AI- and human-involved systems—including data markets, federated learning, and human–AI collaboration. I investigate fairness-related issues arising from human factors such as heterogeneous data resources, behaviors, cognitive capacities, and demographic characteristics. My academic goal is to empower AI systems to be trustworthy, efficient, and fair in practice.

<hr class="divider" />

Artificial Intelligence (AI) has become an integral part of our daily lives, providing efficient, large-scale support for decision-making across various domains such as medical diagnoses, financial risk assessments, and sentencing judgments. Given its close relation to human well-being, it is imperative to examine whether AI acts as an ethical assistant. For example, will AI assistance exacerbate information inequality among diverse human demographics—particularly those with varying expertise due to unequal access to advanced knowledge? Could AI systems propagate subtle biases and mislead humans into making unfair decisions?



During my PhD studies, I actively engaged in examining and solving fairness-related issues in systems involving both humans and AI. These issues include:



- **Data Markets:** Budget-constrained participants seek to purchase datasets that most effectively enhance fairness in AI model training, yet the capacity of marketplace datasets to improve fairness before purchase remains unknown.

- **Collaborative Model Training:**
  - There is a trade-off between allocating model performance fairly among participants and achieving optimal overall performance.
  - Fair performance allocation may sacrifice the benefits of advantaged participants, prompting them to withdraw and potentially causing the system to be unstable.
  - Multi-fairness-aware local model aggregation mechanisms can be stealthily bypassed by malicious participants, undermining the collaboratively trained global model's fairness without reducing accuracy.

- **Human–AI Collaboration:** Experts' utility gains from AI assistance are sensitive to individual factors such as cognitive capacity, resulting in unequal benefits among heterogeneous experts.


I expect to graduate in July 2025 and am currently seeking postdoctoral positions to continue my research. You can find my CV [here]({{site.url}}/assets/pdf/Jiashi_GAO_CV.pdf).
